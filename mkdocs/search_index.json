{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to Moresql Documentation\n\n\nFor basic introduction: \nREADME\n\n\nGithub Repository\n\n\nMoreSQL streams changes occuring in Mongo database into a Postgres db. MoreSQL tails the oplog and generates appropriate actions against Postgres. MoreSQL has the ability to do full synchronizations using UPSERTS, with the benefit over INSERTS that this can be executed against tables with existing data.\n\n\nMoreSQL gives you a chance to use more sql and less mongo query language.\n\n\nCommands\n\n\n\n\nmoresql -tail\n - Start tailing the oplog from mongo and persist to Postgres.\n\n\nmoresql -full-sync\n - Conduct a full sync based on configuration file from mongo-\npg.\n\n\nmoresql -help\n - Usage Instructions.", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-moresql-documentation", 
            "text": "For basic introduction:  README  Github Repository  MoreSQL streams changes occuring in Mongo database into a Postgres db. MoreSQL tails the oplog and generates appropriate actions against Postgres. MoreSQL has the ability to do full synchronizations using UPSERTS, with the benefit over INSERTS that this can be executed against tables with existing data.  MoreSQL gives you a chance to use more sql and less mongo query language.", 
            "title": "Welcome to Moresql Documentation"
        }, 
        {
            "location": "/#commands", 
            "text": "moresql -tail  - Start tailing the oplog from mongo and persist to Postgres.  moresql -full-sync  - Conduct a full sync based on configuration file from mongo- pg.  moresql -help  - Usage Instructions.", 
            "title": "Commands"
        }, 
        {
            "location": "/README/", 
            "text": "MoreSQL\n\n\n\n\n\n\nIntroduction\n\n\nMoreSQL streams changes occuring in Mongo database into a Postgres db. MoreSQL tails the oplog and generates appropriate actions against Postgres. MoreSQL has the ability to do full synchronizations using \nUPSERTS\n, with the benefit over \nINSERTS\n that this can be executed against tables with existing data.\n\n\nMoreSQL gives you a chance to use more sql and less mongo query language.\n\n\nUsage\n\n\nBasic Use\n\n\nTail\n\n\n./moresql -tail -config-file=moresql.json\n\n\nTail is the primary run mode for MoreSQL. When tailing, the oplog is observed for novely and each INSERT/UPDATE/DELETE is translated to its SQL equivalent, then executed against Postgres.\n\n\nTail makes a best faith effort to do this and does not use checkpoint markers to track position in the oplog. It may be introduced in later releases. Or we could introduce a way to split MoreSQL into a producer (oplog tail) that puts records onto stream (Kinesis/Kafka/etc) and a consumer that reads from the stream. By doing so, we'd avoid re-implmenting checkpoints in MoreSQL.\n\n\nGiven that \ntail\n mode executes \nUPSERTS\n instead of \nINSERT || UPDATE\n, we expect MoreSQL to be roughly eventually consistent. We're chosing to prioritize speed of execution (multiple workers) in lieu of some consistency. This helps to keep low latency with larger workloads.\n\n\nFull Sync\n\n\n./moresql -full-sync -config-file=moresql.json\n\n\nFull sync is useful when first setting up a MoreSQL installation to port the existing Mongo data to Postgres. We recommend setting up a tailing instance first. Once that's running, do a full sync in different process. This should put the Mongo and Postgres into identical states.\n\n\nGiven the nature of streaming replica data from Mongo -\n Postgres, it's recommended to run full sync at intervals in order to offset losses that may have occured during network issues, system downtime, etc.\n\n\nDocumentation\n\n\nhttps://zph.github.io/moresql/\n\n\n\n\nQuickStart\n\n\nIntroduction\n\n\n\n\nCreate metadata table\n\n\nSetup moresql.json\n\n\nSetup any recipient tables in postgres\n\n\nValidate with \n./moresql -validate\n\n\nDeploy binary to server\n\n\nConfigure Environmental variables\n\n\nRun \n./moresql -tail\n to start transmitting novelty\n\n\nRun \n./moresql -full-sync\n to populate the database\n\n\n\n\nTable Setup\n\n\n-- Execute the following SQL to setup table in Postgres. Replace $USERNAME with the moresql user.\n-- create the moresql_metadata table for checkpoint persistance\nCREATE TABLE public.moresql_metadata\n(\n    app_name TEXT NOT NULL,\n    last_epoch INT NOT NULL,\n    processed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW() NOT NULL\n);\n-- Setup mandatory unique index\nCREATE UNIQUE INDEX moresql_metadata_app_name_uindex ON public.moresql_metadata (app_name);\n\n-- Grant permissions to this user, replace $USERNAME with moresql's user\nGRANT SELECT, UPDATE, DELETE ON TABLE public.moresql_metadata TO $USERNAME;\n\nCOMMENT ON COLUMN public.moresql_metadata.app_name IS 'Name of application. Used for circumstances where multiple apps stream to same PG instance.';\nCOMMENT ON COLUMN public.moresql_metadata.last_epoch IS 'Most recent epoch processed from Mongo';\nCOMMENT ON COLUMN public.moresql_metadata.processed_at IS 'Timestamp for when the last epoch was processed at';\nCOMMENT ON TABLE public.moresql_metadata IS 'Stores checkpoint data for MoreSQL (mongo-\npg) streaming';\n\n\n\n\nBuilding Binary\n\n\nCompile binary using \nmake build\n\n\nCommandline Arguments / Usage\n\n\nExecute \n./moresql --help\n\n\n./bin/moresql\nRepo https://github.com/zph/moresql\nUsage of ./bin/moresql:\n  -allow-deletes\n     Allow deletes to propagate from Mongo -\n PG (default true)\n  -app-name string\n     AppName used in Checkpoint table (default \nmoresql\n)\n  -checkpoint\n     Store and restore from checkpoints in PG table: moresql_metadata\n  -config-file string\n     Configuration file to use (default \nmoresql.json\n)\n  -create-table-sql\n     Print out the necessary SQL for creating metadata table required for checkpointing\n  -enable-monitor\n     Run expvarmon endpoint\n  -error-reporting string\n     Error reporting tool to use (currently only supporting Rollbar)\n  -full-sync\n     Run full sync for each db.collection in config\n  -memprofile string\n     Profile memory usage. Supply filename for output of memory usage\n  -mongo-url MONGO_URL\n     MONGO_URL aka connection string\n  -postgres-url POSTGRES_URL\n     POSTGRES_URL aka connection string\n  -replay-duration duration\n     Last x to replay ie '1s', '5m', etc as parsed by Time.ParseDuration. Will be subtracted from time.Now()\n  -replay-second int\n     Replay a specific epoch second of the oplog and forward from there.\n  -ssl-cert string\n     SSL PEM cert for Mongodb\n  -tail\n     Tail mongodb for each db.collection in config\n  -validate\n     Validate the postgres table structures and exit\n\n\n\n\nValidation of Configuration + Postgres Schema\n\n\n./moresql -validate\n\n\nThis will report any issues related to the postgres schema being a mis-match for the fields and tables setup in configuration.\n\n\nRequirements, Stability and Versioning\n\n\nMoreSQL is expected and built with Golang 1.6, 1.7 and master in mind. Broken tests on these versions indicates a bug.\n\n\nMoreSQL requires Postgres 9.5+ due to usage of UPSERTs. Using UPSERTs simplifies internal logic but also depends on UNIQUE indexes existing on each \n_id\n column in Postgres. See \nmoresql -validate\n for advice.\n\n\nMiscellanea\n\n\nError Reporting\n\n\nAvailable through Rollbar. PRs welcome for other services. We currently use Rollus\nwhich reports errors synchronously. If this is a performance bottleneck please PR or issue.\n\n\nEnable this by two steps:\n\n\nexport ERROR_REPORTING_TOKEN=asdfasdfasdf\nexport APP_ENV=[production, development, or staging]\n\n\n\n\nAnd when running application use the following flag to enable reporting:\n\n\n./moresql -tail -error-reporting \"rollbar\"\n\n\nIf these steps are not followed, errors will be reported out solely via logging.\n\n\nEnvironmental Variables used in Moresql\n\n\nMONGO_URL\nPOSTGRES_URL\nERROR_REPORTING_TOKEN\nAPP_ENV\nDYNO\nLOG_LEVEL\n\n\n\n\nMongo types\n\n\nWe guard against a few of these for conversion into Postgres friendly types.\n\n\nObjects and Arrays do not behave properly when inserting into Postgres. These will be automatically converted into their JSON representation before inserting into Postgres.\n\n\nAs of writing, any BsonID/ObjectId should be noted as \nid\n type in \nFields.Mongo.Type\n to facilitate this. In the future we may assume that all fields ending in \n_id\n are Id based fields and require conversion.\n\n\nConverting from MoSQL\n\n\nRun the ./bin/convert_config_from_mosql_to_moresql script in a folder with \ncollections.yml\n\n\nruby ./bin/convert_config_from_mosql_to_moresql collection.yml\n\n\n\n\nThe generated file \nmoresql.json\n will be in place ready for use.\n\n\nUnsupported Features\n\n\nThese features are part of mosql but not implemented in MoreSQL. PRs welcome.\n\n\n\n\nDot Notation for nested structures\n\n\nextra_props field for spare data\n\n\nAutomatic creation of tables/columns\n\n\n\n\nPerformance\n\n\nDuring benchmarking when moresql is asked to replay existing events from oplog we've seen the following performance with the following configurations:\n\n\n5 workers per collection\n500 generic workers\nOn a Heroku 1X dyno\n\n\n~ $ ./moresql -tail -replay-duration \n5000m\n | grep \nRate of\n\n{\nlevel\n:\ninfo\n,\nmsg\n:\nRate of insert per min: 532\n,\ntime\n:\n2017-02-23T01:49:31Z\n}\n{\nlevel\n:\ninfo\n,\nmsg\n:\nRate of update per min: 44089\n,\ntime\n:\n2017-02-23T01:49:31Z\n}\n{\nlevel\n:\ninfo\n,\nmsg\n:\nRate of delete per min: 1\n,\ntime\n:\n2017-02-23T01:49:31Z\n}\n{\nlevel\n:\ninfo\n,\nmsg\n:\nRate of read per min: 91209\n,\ntime\n:\n2017-02-23T01:49:31Z\n}\n{\nlevel\n:\ninfo\n,\nmsg\n:\nRate of skipped per min: 46587\n,\ntime\n:\n2017-02-23T01:49:31Z\n}\n\n\n\n\nApproximately 700 updates/sec and 1500 reads/sec is our top observed throughput so far. Please submit PRs with further numbers using a similar command.\n\n\nWe expect the following bottlenecks: connection count in Postgres, pg connection limitations in Moresql (for safety), network bandwidth, worker availability.\n\n\nAt this level of throughput, Moresql uses ~90MB RAM. At low idle throughput of 10-20 req/sec it consumes ~30MB RAM.\n\n\nIn another benchmark when updating 28k documents simultaneously, we observed mean lag of ~ 500ms and 95% of requests arrived in \n= 1194ms between when the document was updated in Mongo and when it arrived in Postgres.\n\n\nSee full \nperformance information\n\n\nFor a general discussion of UPSERT performance in Postgres: https://mark.zealey.org/2016/01/08/how-we-tweaked-postgres-upsert-performance-to-be-2-3-faster-than-mongodb\n\n\nBinaries\n\n\nWe release binaries for semvar tags on Github Releases page using \ngoreleaser\n for the platforms listed in goreleaser.yml.\n\n\nCredit and Prior Art\n\n\n\n\nMoSQL\n - the project we used for 3 yrs at work and then retired with MoreSQL. Thanks Stripe!\n\n\nGTM\n - the go library that builds on mgo to wrap the tailing and oplog interface in a pleasant API. rwynn was a large help with improving GTM's performance with varying levels of consistency guarantees.", 
            "title": "Readme"
        }, 
        {
            "location": "/README/#moresql", 
            "text": "", 
            "title": "MoreSQL"
        }, 
        {
            "location": "/README/#introduction", 
            "text": "MoreSQL streams changes occuring in Mongo database into a Postgres db. MoreSQL tails the oplog and generates appropriate actions against Postgres. MoreSQL has the ability to do full synchronizations using  UPSERTS , with the benefit over  INSERTS  that this can be executed against tables with existing data.  MoreSQL gives you a chance to use more sql and less mongo query language.", 
            "title": "Introduction"
        }, 
        {
            "location": "/README/#usage", 
            "text": "", 
            "title": "Usage"
        }, 
        {
            "location": "/README/#basic-use", 
            "text": "", 
            "title": "Basic Use"
        }, 
        {
            "location": "/README/#tail", 
            "text": "./moresql -tail -config-file=moresql.json  Tail is the primary run mode for MoreSQL. When tailing, the oplog is observed for novely and each INSERT/UPDATE/DELETE is translated to its SQL equivalent, then executed against Postgres.  Tail makes a best faith effort to do this and does not use checkpoint markers to track position in the oplog. It may be introduced in later releases. Or we could introduce a way to split MoreSQL into a producer (oplog tail) that puts records onto stream (Kinesis/Kafka/etc) and a consumer that reads from the stream. By doing so, we'd avoid re-implmenting checkpoints in MoreSQL.  Given that  tail  mode executes  UPSERTS  instead of  INSERT || UPDATE , we expect MoreSQL to be roughly eventually consistent. We're chosing to prioritize speed of execution (multiple workers) in lieu of some consistency. This helps to keep low latency with larger workloads.", 
            "title": "Tail"
        }, 
        {
            "location": "/README/#full-sync", 
            "text": "./moresql -full-sync -config-file=moresql.json  Full sync is useful when first setting up a MoreSQL installation to port the existing Mongo data to Postgres. We recommend setting up a tailing instance first. Once that's running, do a full sync in different process. This should put the Mongo and Postgres into identical states.  Given the nature of streaming replica data from Mongo -  Postgres, it's recommended to run full sync at intervals in order to offset losses that may have occured during network issues, system downtime, etc.", 
            "title": "Full Sync"
        }, 
        {
            "location": "/README/#documentation", 
            "text": "https://zph.github.io/moresql/", 
            "title": "Documentation"
        }, 
        {
            "location": "/README/#quickstart", 
            "text": "", 
            "title": "QuickStart"
        }, 
        {
            "location": "/README/#introduction_1", 
            "text": "Create metadata table  Setup moresql.json  Setup any recipient tables in postgres  Validate with  ./moresql -validate  Deploy binary to server  Configure Environmental variables  Run  ./moresql -tail  to start transmitting novelty  Run  ./moresql -full-sync  to populate the database", 
            "title": "Introduction"
        }, 
        {
            "location": "/README/#table-setup", 
            "text": "-- Execute the following SQL to setup table in Postgres. Replace $USERNAME with the moresql user.\n-- create the moresql_metadata table for checkpoint persistance\nCREATE TABLE public.moresql_metadata\n(\n    app_name TEXT NOT NULL,\n    last_epoch INT NOT NULL,\n    processed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW() NOT NULL\n);\n-- Setup mandatory unique index\nCREATE UNIQUE INDEX moresql_metadata_app_name_uindex ON public.moresql_metadata (app_name);\n\n-- Grant permissions to this user, replace $USERNAME with moresql's user\nGRANT SELECT, UPDATE, DELETE ON TABLE public.moresql_metadata TO $USERNAME;\n\nCOMMENT ON COLUMN public.moresql_metadata.app_name IS 'Name of application. Used for circumstances where multiple apps stream to same PG instance.';\nCOMMENT ON COLUMN public.moresql_metadata.last_epoch IS 'Most recent epoch processed from Mongo';\nCOMMENT ON COLUMN public.moresql_metadata.processed_at IS 'Timestamp for when the last epoch was processed at';\nCOMMENT ON TABLE public.moresql_metadata IS 'Stores checkpoint data for MoreSQL (mongo- pg) streaming';", 
            "title": "Table Setup"
        }, 
        {
            "location": "/README/#building-binary", 
            "text": "Compile binary using  make build", 
            "title": "Building Binary"
        }, 
        {
            "location": "/README/#commandline-arguments-usage", 
            "text": "Execute  ./moresql --help  ./bin/moresql\nRepo https://github.com/zph/moresql\nUsage of ./bin/moresql:\n  -allow-deletes\n     Allow deletes to propagate from Mongo -  PG (default true)\n  -app-name string\n     AppName used in Checkpoint table (default  moresql )\n  -checkpoint\n     Store and restore from checkpoints in PG table: moresql_metadata\n  -config-file string\n     Configuration file to use (default  moresql.json )\n  -create-table-sql\n     Print out the necessary SQL for creating metadata table required for checkpointing\n  -enable-monitor\n     Run expvarmon endpoint\n  -error-reporting string\n     Error reporting tool to use (currently only supporting Rollbar)\n  -full-sync\n     Run full sync for each db.collection in config\n  -memprofile string\n     Profile memory usage. Supply filename for output of memory usage\n  -mongo-url MONGO_URL\n     MONGO_URL aka connection string\n  -postgres-url POSTGRES_URL\n     POSTGRES_URL aka connection string\n  -replay-duration duration\n     Last x to replay ie '1s', '5m', etc as parsed by Time.ParseDuration. Will be subtracted from time.Now()\n  -replay-second int\n     Replay a specific epoch second of the oplog and forward from there.\n  -ssl-cert string\n     SSL PEM cert for Mongodb\n  -tail\n     Tail mongodb for each db.collection in config\n  -validate\n     Validate the postgres table structures and exit", 
            "title": "Commandline Arguments / Usage"
        }, 
        {
            "location": "/README/#validation-of-configuration-postgres-schema", 
            "text": "./moresql -validate  This will report any issues related to the postgres schema being a mis-match for the fields and tables setup in configuration.", 
            "title": "Validation of Configuration + Postgres Schema"
        }, 
        {
            "location": "/README/#requirements-stability-and-versioning", 
            "text": "MoreSQL is expected and built with Golang 1.6, 1.7 and master in mind. Broken tests on these versions indicates a bug.  MoreSQL requires Postgres 9.5+ due to usage of UPSERTs. Using UPSERTs simplifies internal logic but also depends on UNIQUE indexes existing on each  _id  column in Postgres. See  moresql -validate  for advice.", 
            "title": "Requirements, Stability and Versioning"
        }, 
        {
            "location": "/README/#miscellanea", 
            "text": "", 
            "title": "Miscellanea"
        }, 
        {
            "location": "/README/#error-reporting", 
            "text": "Available through Rollbar. PRs welcome for other services. We currently use Rollus\nwhich reports errors synchronously. If this is a performance bottleneck please PR or issue.  Enable this by two steps:  export ERROR_REPORTING_TOKEN=asdfasdfasdf\nexport APP_ENV=[production, development, or staging]  And when running application use the following flag to enable reporting:  ./moresql -tail -error-reporting \"rollbar\"  If these steps are not followed, errors will be reported out solely via logging.", 
            "title": "Error Reporting"
        }, 
        {
            "location": "/README/#environmental-variables-used-in-moresql", 
            "text": "MONGO_URL\nPOSTGRES_URL\nERROR_REPORTING_TOKEN\nAPP_ENV\nDYNO\nLOG_LEVEL", 
            "title": "Environmental Variables used in Moresql"
        }, 
        {
            "location": "/README/#mongo-types", 
            "text": "We guard against a few of these for conversion into Postgres friendly types.  Objects and Arrays do not behave properly when inserting into Postgres. These will be automatically converted into their JSON representation before inserting into Postgres.  As of writing, any BsonID/ObjectId should be noted as  id  type in  Fields.Mongo.Type  to facilitate this. In the future we may assume that all fields ending in  _id  are Id based fields and require conversion.", 
            "title": "Mongo types"
        }, 
        {
            "location": "/README/#converting-from-mosql", 
            "text": "Run the ./bin/convert_config_from_mosql_to_moresql script in a folder with  collections.yml  ruby ./bin/convert_config_from_mosql_to_moresql collection.yml  The generated file  moresql.json  will be in place ready for use.", 
            "title": "Converting from MoSQL"
        }, 
        {
            "location": "/README/#unsupported-features", 
            "text": "These features are part of mosql but not implemented in MoreSQL. PRs welcome.   Dot Notation for nested structures  extra_props field for spare data  Automatic creation of tables/columns", 
            "title": "Unsupported Features"
        }, 
        {
            "location": "/README/#performance", 
            "text": "During benchmarking when moresql is asked to replay existing events from oplog we've seen the following performance with the following configurations:  5 workers per collection\n500 generic workers\nOn a Heroku 1X dyno  ~ $ ./moresql -tail -replay-duration  5000m  | grep  Rate of \n{ level : info , msg : Rate of insert per min: 532 , time : 2017-02-23T01:49:31Z }\n{ level : info , msg : Rate of update per min: 44089 , time : 2017-02-23T01:49:31Z }\n{ level : info , msg : Rate of delete per min: 1 , time : 2017-02-23T01:49:31Z }\n{ level : info , msg : Rate of read per min: 91209 , time : 2017-02-23T01:49:31Z }\n{ level : info , msg : Rate of skipped per min: 46587 , time : 2017-02-23T01:49:31Z }  Approximately 700 updates/sec and 1500 reads/sec is our top observed throughput so far. Please submit PRs with further numbers using a similar command.  We expect the following bottlenecks: connection count in Postgres, pg connection limitations in Moresql (for safety), network bandwidth, worker availability.  At this level of throughput, Moresql uses ~90MB RAM. At low idle throughput of 10-20 req/sec it consumes ~30MB RAM.  In another benchmark when updating 28k documents simultaneously, we observed mean lag of ~ 500ms and 95% of requests arrived in  = 1194ms between when the document was updated in Mongo and when it arrived in Postgres.  See full  performance information  For a general discussion of UPSERT performance in Postgres: https://mark.zealey.org/2016/01/08/how-we-tweaked-postgres-upsert-performance-to-be-2-3-faster-than-mongodb", 
            "title": "Performance"
        }, 
        {
            "location": "/README/#binaries", 
            "text": "We release binaries for semvar tags on Github Releases page using  goreleaser  for the platforms listed in goreleaser.yml.", 
            "title": "Binaries"
        }, 
        {
            "location": "/README/#credit-and-prior-art", 
            "text": "MoSQL  - the project we used for 3 yrs at work and then retired with MoreSQL. Thanks Stripe!  GTM  - the go library that builds on mgo to wrap the tailing and oplog interface in a pleasant API. rwynn was a large help with improving GTM's performance with varying levels of consistency guarantees.", 
            "title": "Credit and Prior Art"
        }, 
        {
            "location": "/deploying/", 
            "text": "Deploying\n\n\nOn Server\n\n\n\n\nDownload release or compile binary for platform\n\n\nFollow \nsetup guide for MoreSQL\n\n\nSet environmental variables\n\n\nRun moresql under process manager\n\n\n\n\nOn Heroku\n\n\n\n\n\n\nFollow \nsetup guide for MoreSQL\n\n\n\n\n\n\nCreate repository for deployment\n\n\n\n\n\n\nCreate Procfile\n\n\n\n\n\n\nSample:\n\n\nworker: ./moresql -tail -checkpoint -error-reporting \nrollbar\n\n\n\n\n\n\n\n\n\nSet the ENV variables according to README \nsection\n\n\n\n\n\n\nDownload latest stable release of moresql or build yourself for the linux amd64 platform using cross compilation\n\n\n\n\n\n\nCommit that binary to deploy project\n\n\n\n\n\n\nAdd null buildpack for using a binary on heroku\n\n\n\n\n\n\nheroku buildpacks:set -r REMOTE_NAME https://github.com/ryandotsmith/null-buildpack.git#72915d8b59f0f089931b4ed3b9c9b6f1750c331a\n\n\n\n\nNote: we pin to specific version of buildpack so future upgrades aren't automatically applied.\n\n\n\n\nDeploy to heroku with a git push", 
            "title": "Deploy"
        }, 
        {
            "location": "/deploying/#deploying", 
            "text": "", 
            "title": "Deploying"
        }, 
        {
            "location": "/deploying/#on-server", 
            "text": "Download release or compile binary for platform  Follow  setup guide for MoreSQL  Set environmental variables  Run moresql under process manager", 
            "title": "On Server"
        }, 
        {
            "location": "/deploying/#on-heroku", 
            "text": "Follow  setup guide for MoreSQL    Create repository for deployment    Create Procfile    Sample:  worker: ./moresql -tail -checkpoint -error-reporting  rollbar     Set the ENV variables according to README  section    Download latest stable release of moresql or build yourself for the linux amd64 platform using cross compilation    Commit that binary to deploy project    Add null buildpack for using a binary on heroku    heroku buildpacks:set -r REMOTE_NAME https://github.com/ryandotsmith/null-buildpack.git#72915d8b59f0f089931b4ed3b9c9b6f1750c331a  Note: we pin to specific version of buildpack so future upgrades aren't automatically applied.   Deploy to heroku with a git push", 
            "title": "On Heroku"
        }, 
        {
            "location": "/TODO/", 
            "text": "TODOs\n\n\nTO DEPLOY and RELEASE\n\n\n\n\n[x] Add checkpointing in case of downtime\n\n\n[x] Make it set on timer, ie every minute or configurable duration\n\n\n[x] determine if we want to play catch up in oplog or not  (get oldest db.oplog.rs.find().sort({ts:-1}).limit(1))\n\n\n[x] Make sure that multiple moresqls can insert their marker on same db meta table\n\n\n[x] Add conversion from MoSQL to MoreSQL\n\n\n[x] Add quickstart guide and gh pages or link to godoc\n\n\n[x] Add starter SQL script for checkpointing script\n\n\n[x] Add validation cmdline flag to compare configuration with PG tables/columns\n\n\n[x] Add documentation for deploying on Heroku via null buildpack\n\n\n[x] Verify that log statements are set at appropriate levels, ie warn/error/etc\n\n\n[x] Test in staging, then production\n\n\n[x] Bake binary in production\n\n\n[ ] Release and announce project to the world\n\n\n\n\nDESIRED\n\n\n\n\n[ ] Use dot notation for config description of nested maps, ie allow for \nget_in(\"outerkey\", \"innerkey\")\n as \nouterkey.innerkey\n by using https://github.com/tidwall/gjson\n\n\n[ ] Improve library testing (unit and integration/system). Potentially using docker for full trip integration tests.\n\n\n[x] Refactor tail to have a producer/consumer as Read/Write\n\n\n[x] Setup https://github.com/thejerf/suture wrappers on components\n\n\n[x] Add testing and refactor to make each bit fairly decoupled\n\n\n[x] Include docs and scripts to transition from mosql to moresql\n\n\n[x] Setup formal worker pool along with overflow pool of workers\n\n\n[x] add tracking mechanism for missing/broken tables beyond \"log it into abyss\".\n\n\n[x] add error handling with rollbar/bugsnag/etc\n\n\n\n\nSOMEDAYs\n\n\n\n\n[ ] Setup system tests (https://www.elastic.co/blog/code-coverage-for-your-golang-system-tests)\n\n\n[ ] Add basic auth and SSL for endpoint of expvarmon\n\n\n[ ] add signal handling for SIGTERM to flush existing content in buffers then exit\n\n\n[ ] add expvar.Publish for backlog of all events waiting to process in \nfan\n\n\n[ ] time operates on int64, suggest that gtm.ParseTimestamp do likewise for interop\n\n\n[ ] Make library generic with regard to event destination. Could be expanded out as a bridge Mongo-\n{Kinesis,Kafka,Postgres,MySQL}\n\n\n[ ] https://github.com/zph/moresql/blob/master/full_sync.go#L135\n\n\n[ ] Make the writer function configurable with postgres as the default\n\n\n[ ] Writers should fit the interface of accepting a pointer to tables struct and the channel of incoming operations\n\n\n[ ] All of https://github.com/zph/moresql/blob/master/full_sync.go#L129-L136 should be inside the writer function as it will differ by output sink.\n\n\n[ ] Support nested fetching ala \nuser.name\n to extract 2 levels deep", 
            "title": "TODOs"
        }, 
        {
            "location": "/TODO/#todos", 
            "text": "", 
            "title": "TODOs"
        }, 
        {
            "location": "/TODO/#to-deploy-and-release", 
            "text": "[x] Add checkpointing in case of downtime  [x] Make it set on timer, ie every minute or configurable duration  [x] determine if we want to play catch up in oplog or not  (get oldest db.oplog.rs.find().sort({ts:-1}).limit(1))  [x] Make sure that multiple moresqls can insert their marker on same db meta table  [x] Add conversion from MoSQL to MoreSQL  [x] Add quickstart guide and gh pages or link to godoc  [x] Add starter SQL script for checkpointing script  [x] Add validation cmdline flag to compare configuration with PG tables/columns  [x] Add documentation for deploying on Heroku via null buildpack  [x] Verify that log statements are set at appropriate levels, ie warn/error/etc  [x] Test in staging, then production  [x] Bake binary in production  [ ] Release and announce project to the world", 
            "title": "TO DEPLOY and RELEASE"
        }, 
        {
            "location": "/TODO/#desired", 
            "text": "[ ] Use dot notation for config description of nested maps, ie allow for  get_in(\"outerkey\", \"innerkey\")  as  outerkey.innerkey  by using https://github.com/tidwall/gjson  [ ] Improve library testing (unit and integration/system). Potentially using docker for full trip integration tests.  [x] Refactor tail to have a producer/consumer as Read/Write  [x] Setup https://github.com/thejerf/suture wrappers on components  [x] Add testing and refactor to make each bit fairly decoupled  [x] Include docs and scripts to transition from mosql to moresql  [x] Setup formal worker pool along with overflow pool of workers  [x] add tracking mechanism for missing/broken tables beyond \"log it into abyss\".  [x] add error handling with rollbar/bugsnag/etc", 
            "title": "DESIRED"
        }, 
        {
            "location": "/TODO/#somedays", 
            "text": "[ ] Setup system tests (https://www.elastic.co/blog/code-coverage-for-your-golang-system-tests)  [ ] Add basic auth and SSL for endpoint of expvarmon  [ ] add signal handling for SIGTERM to flush existing content in buffers then exit  [ ] add expvar.Publish for backlog of all events waiting to process in  fan  [ ] time operates on int64, suggest that gtm.ParseTimestamp do likewise for interop  [ ] Make library generic with regard to event destination. Could be expanded out as a bridge Mongo- {Kinesis,Kafka,Postgres,MySQL}  [ ] https://github.com/zph/moresql/blob/master/full_sync.go#L135  [ ] Make the writer function configurable with postgres as the default  [ ] Writers should fit the interface of accepting a pointer to tables struct and the channel of incoming operations  [ ] All of https://github.com/zph/moresql/blob/master/full_sync.go#L129-L136 should be inside the writer function as it will differ by output sink.  [ ] Support nested fetching ala  user.name  to extract 2 levels deep", 
            "title": "SOMEDAYs"
        }, 
        {
            "location": "/performance/", 
            "text": "Performance of MoreSQL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode{white-space: pre;}\n\n\n\n\n  pre:not([class]) {\n    background-color: white;\n  }\n\n\n\n\n\nif (window.hljs && document.readyState && document.readyState === \"complete\") {\n   window.setTimeout(function() {\n      hljs.initHighlighting();\n   }, 0);\n}\n\n\n\n\n\nh1 {\n  font-size: 34px;\n}\nh1.title {\n  font-size: 38px;\n}\nh2 {\n  font-size: 30px;\n}\nh3 {\n  font-size: 24px;\n}\nh4 {\n  font-size: 18px;\n}\nh5 {\n  font-size: 16px;\n}\nh6 {\n  font-size: 12px;\n}\n.table th:not([align]) {\n  text-align: left;\n}\n#rmd-source-code {\n  display: none;\n}\n\n\n\n\n\n\n\n\n\n.main-container {\n  max-width: 940px;\n  margin-left: auto;\n  margin-right: auto;\n}\ncode {\n  color: inherit;\n  background-color: rgba(0, 0, 0, 0.04);\n}\nimg {\n  max-width:100%;\n  height: auto;\n}\n.tabbed-pane {\n  padding-top: 12px;\n}\nbutton.code-folding-btn:focus {\n  outline: none;\n}\n\n\n\n\n\n.kable-table {\n  border: 1px solid #ccc;\n  border-radius: 4px;\n  overflow: auto;\n  padding-left: 8px;\n  padding-right: 8px;\n  margin-bottom: 20px;\n  max-height: 350px;\n}\n\n.kable-table table {\n  margin-bottom: 0px;\n}\n\n.kable-table table>thead>tr>th {\n  border: none;\n  border-bottom: 2px solid #dddddd;\n}\n\n.kable-table table>thead {\n  background-color: #fff;\n}\n\n\n\n\n\n\n\n\n\n\n$(document).ready(function () {\n  window.buildTabsets(\"TOC\");\n});\n\n\n\n\n\n\n\n.code-folding-btn { margin-bottom: 4px; }\n\n\n\n\n$(document).ready(function () {\n  window.initializeSourceEmbed(\"performance.Rmd\");\n  window.initializeCodeFolding(\"show\" === \"show\");\n});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n \n\n\n\n\nShow All Code\n\n\nHide All Code\n\n\n\n\nDownload Rmd\n\n\n\n\n\n\n\n\n\nPerformance of MoreSQL\n\n\n\n\n\n\n\n\n\nCharts the performance of MoreSQL lag on a Heroku dyno.\n\n\n\n\n\n\n\n\nLatency From Mongo-\nPostgres As Measured by Postgres Trigger\n\n\n\n\nMethodology\n\n\nSetup postgres trigger that measures latency between updated_at field and \nNOW()\n. Then trigger many (28k) updates. Record the trigger payloads and plot using RMarkdown.\n\n\nFor this measurement, we setup a postgres trigger that fires when any record on given collection is updated. We then updated the 28k records in that collection.\n\n\nUsing a postgres trigger combined with object touch in mongo allows us to see millisecond precision, which is not possible using bson.MongoTimestamp data.\n\n\n\n\n\n\nTrigger in Postgres\n\n\n-- Trigger for pushing data onto notify channel\nCREATE OR REPLACE FUNCTION notify_row_changes()\n    RETURNS trigger AS $$\nDECLARE\n    current_row RECORD;\n    old_row json;\n    new_row json;\nBEGIN\n    IF TG_OP IN ('INSERT', 'UPDATE') THEN\n        current_row := NEW;\n        new_row := row_to_json(NEW);\n    ELSE\n        current_row := OLD;\n        new_row := '{}'::json;\n    END IF;\n    IF TG_OP = 'INSERT' THEN\n        old_row := '{}'::json;\n    ELSEIF TG_OP IN ('UPDATE', 'DELETE') THEN\n        old_row := row_to_json(OLD);\n    END IF;\n    PERFORM pg_notify(\n        'row_changes',\n        json_build_object(\n            'timestamp', NOW(),\n            'uuid', uuid_generate_v4(),\n            'table', TG_TABLE_NAME,\n            'action', TG_OP,\n            '_id', current_row._id,\n            'updated_at', current_row.updated_at,\n            'ms_lag', extract(MILLISECONDS from INTERVAL '08:00' + NOW() - current_row.updated_at)\n        )::text\n    );\n    RETURN current_row;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER changes_to_row_trigger BEFORE insert or update or delete ON sample_items\nFOR EACH ROW EXECUTE PROCEDURE notify_row_changes();\n\n\n\n\n\n\nms_lag was calculated as follows:\n\n\nextract(MILLISECONDS from INTERVAL '08:00' + NOW() - updated_at) as ms_lag\n\n\n\n\n\n\nThe trigger output\n\n\nNOTIFY\u2019s output was observed using Postgres\u2019s LISTEN functionality and a payload was delivered in the following schema:\n\n\n{\n  \ntimestamp\n: \n2017-02-24T00:08:20.91831+00:00\n,\n  \nuuid\n: \ne25ec752-7de3-4de0-b764-bdac9af1a05b\n,\n  \ntable\n: \nsample_items\n,\n  \naction\n: \nINSERT\n,\n  \n_id\n: \n4f60c45452e7520003000018\n,\n  \nupdated_at\n: \n2017-02-24T00:08:20.371\n,\n  \nms_lag\n: 547.31\n}\n\n\n\n\n\n\n\n\nResults\n\n\n\n\n\n\n\n\ndf \n- build_df(\nms_lag_from_28000_entries_calculated_by_trigger.log\n)\nprint_quantile(df)\n\n\n\n\n\n\n[1] \nMean latency: 585.585214235771\n\n[1] \nQuantile by % Chance Latency will be \n= this duration (ms)\n\n      25%       50%       75%       90%       95%       98%       99%      100% \n 383.3840  529.2315  713.8370 1063.5870 1194.5130 1288.7950 1330.8820 1476.4480 \n\n\n\n\n\n\nprint_histogram(df, \nHistogram of ms_lag vs count\n, \nms_lag\n, \ncount\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConclusion\n\n\nLooking at the Quantile percentages when testing out MoreSQL, 50% of requests come through with 529ms or less of lag. 90% of requests were processed in trigger with 1063ms of lag or less. 100% of requests came through in 1500ms of lag or less.\n\n\n\n\n\n\n\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\n\n\n\n\n\n\n\n\n\n\n// add bootstrap table styles to pandoc tables\nfunction bootstrapStylePandocTables() {\n  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');\n}\n$(document).ready(function () {\n  bootstrapStylePandocTables();\n});\n\n$(document).ready(function () {\n  $('.knitsql-table').addClass('kable-table');\n  var container = $('.kable-table');\n  container.each(function() {\n\n    // move the caption out of the table\n    var table = $(this).children('table');\n    var caption = table.children('caption').detach();\n    caption.insertBefore($(this)).css('display', 'inherit');\n  });\n});\n\n\n\n\n\n\n\n\n\n  (function () {\n    var script = document.createElement(\"script\");\n    script.type = \"text/javascript\";\n    script.src  = \"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\";\n    document.getElementsByTagName(\"head\")[0].appendChild(script);\n  })();", 
            "title": "Performance"
        }
    ]
}